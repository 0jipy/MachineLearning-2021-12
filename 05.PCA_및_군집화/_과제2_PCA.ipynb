{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer data _ PCA\n",
    " - 2,5,10 차원축소 _ 설명력 표현\n",
    " - PCA 전후 분류 비교 (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - 위스콘신 유방암 예측 데이터 분류모델\n",
    "    - sklearn dataset (data, feature, target 등 준비되어있어)\n",
    "    - seaborn pairplot그리고 싶다면 pd.DataFrame 화 해야.\n",
    "    - PCA객체 생성 처음 from sklearn.decomposition import PCA 챙기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "br = load_breast_cancer()\n",
    "# type(br)   ; 타입은 sklearn.utils.Bunch \n",
    "# 판다스 df 화 하지 않고. 정보를 조사해보면\n",
    "# print(br.DESCR)\n",
    "# br.feature_names\n",
    "# br.target_names  : malignant 악성이 0 , 'benign 양성이 1 로 설정되어있어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# br.feature_names\n",
    "br.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피쳐셀렉트 없이 pairplot 돌리지 마요. 제 노트북은 6분 걸렸습니다...! 멈춰!\n",
    "# pairplot은 df넣어줘야해서 오류날것. \n",
    "# df으로 넣어주면 잘 되지 않을까?\n",
    "df  = pd.DataFrame(br.data, columns=br.feature_names)\n",
    "# sns.pairplot(df)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "br = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "br_std = StandardScaler().fit_transform(br.data)\n",
    "br_std[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10, 5, 2 차원순으로 PCA 차원축소 후 설명력 도시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.44272026, 0.18971182, 0.09393163, 0.06602135, 0.05495768,\n",
       "        0.04024522, 0.02250734, 0.01588724, 0.01389649, 0.01168978]),\n",
       " 0.9515688143059359)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA객체 생성\n",
    "from sklearn.decomposition import PCA\n",
    "pca10 = PCA(n_components=10)\n",
    "br_pca10 = pca10.fit_transform(br_std)\n",
    "pca10.explained_variance_ratio_, sum(pca10.explained_variance_ratio_)\n",
    "# 95% 설명력 10 차원에 대해서. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.44272026, 0.18971182, 0.09393163, 0.06602135, 0.05495768]),\n",
       " 0.8473427431679875)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca5 = PCA(n_components=5)\n",
    "br_pca5 = pca5.fit_transform(br_std)\n",
    "pca5.explained_variance_ratio_, sum(pca5.explained_variance_ratio_)\n",
    "# 84% 설명력 5 차원에 대해서. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.44272026, 0.18971182]), 0.6324320765155941)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2 = PCA(n_components=2)\n",
    "br_pca2 = pca2.fit_transform(br_std)\n",
    "pca2.explained_variance_ratio_, sum(pca2.explained_variance_ratio_)\n",
    "# 63% 설명력 2 차원에 대해서. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.44272026, 0.18971182, 0.09393163, 0.06602135, 0.05495768,\n",
       "        0.04024522, 0.02250734, 0.01588724, 0.01389649, 0.01168978]),\n",
       " 0.9515688143328528)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pca10.explained_variance_ratio_, sum(pca10.explained_variance_ratio_)\n",
    "# # 95% 설명력 10 차원에 대해서. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca 설명력 _ 10차원 : 0.95%,  5차원 : 0.85%,  2차원 : 0.63%\n"
     ]
    }
   ],
   "source": [
    "# explained_variance_ratio\n",
    "d = round(sum(pca10.explained_variance_ratio_),2)\n",
    "f = round(sum(pca5.explained_variance_ratio_),2)\n",
    "g = round(sum(pca2.explained_variance_ratio_),2)\n",
    "print( f'pca 설명력 _ 10차원 : {d}%,  5차원 : {f}%,  2차원 : {g}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PCA전후 분류 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA전후 분류비교 \n",
    "# 랜덤 포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA전 accuracy : 0.98\n"
     ]
    }
   ],
   "source": [
    "# PCA전 원본데이터 \n",
    "# 랜덤포레스트의 성능(score)를 accuracy라고 표현하면..??? 뭔가 안맞는듯.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    br.data, br.target, stratify=br.target,  random_state=2021\n",
    ")\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=2021)\n",
    "rfc.fit(X_train, y_train)\n",
    "score = rfc.score(X_test, y_test)\n",
    "print(f\"PCA전 accuracy : {score:.2f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_accuracy(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=br.target,  random_state=2021\n",
    "    )\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(X_train, y_train)\n",
    "    score = rfc.score(X_test, y_test)\n",
    "    return score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 10: 설명력 0.9516, 정확도 0.9650\n",
      "PCA 5: 설명력 0.8473, 정확도 0.9650\n",
      "PCA 2: 설명력 0.6324, 정확도 0.9441\n"
     ]
    }
   ],
   "source": [
    "for n in [10,5,2]:\n",
    "    pca = PCA(n_components=n)\n",
    "    br_pca = pca.fit_transform(br_std)\n",
    "    explained = sum(pca.explained_variance_ratio_)\n",
    "    acc = pca_accuracy(br_pca, br.target)\n",
    "    print(f'PCA {n}: 설명력 {explained:.4f}, 정확도 {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  cf, cell #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 10차원\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     br_pca10, br.target, stratify=br.target,  random_state=2021\n",
    "# )\n",
    "\n",
    "# rfc = RandomForestClassifier()\n",
    "# rfc.fit(X_train, y_train)\n",
    "# rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965034965034965"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 5차원\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     br_pca5, br.target, stratify=br.target,  random_state=2021\n",
    "# )\n",
    "\n",
    "# rfc = RandomForestClassifier()\n",
    "# rfc.fit(X_train, y_train)\n",
    "# rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 2차원\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     br_pca2, br.target, stratify=br.target,  random_state=2021\n",
    "# )\n",
    "\n",
    "# rfc = RandomForestClassifier()\n",
    "# rfc.fit(X_train, y_train)\n",
    "# rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쌤과 함께. 그리고 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     - 2, 5, 10 차원축소\n",
    "     - 원본과 차원축소한 데이터의 분류 정확도 비교\n",
    "     - 2차원 축소한 것은 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 로드 및 정규화 (PCA하려면 무조건)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "df= pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df[\"target\"] = cancer.target\n",
    "# df.target.value_counts()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "cancer_std = StandardScaler().fit_transform(cancer.data)\n",
    "# cancer_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 차원축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 용재씨 질문 고민해볼것. 일단 2차원 차원축소.. 왜 정규화를 해야하는가?\n",
    "\n",
    "# 어떤때 정규화를 하는지 보자. 정규화를 하는 의미 생각. 데이터를 스케일링 했을때의 이점. \n",
    "# PCA는 정규화가 필요할 수 밖에 없다\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44272026, 0.18971182])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "cancer_pca = pca.fit_transform(cancer_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA 전후 분류정확도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer_std, cancer.target, stratify=cancer.target, test_size=0.2, random_state=2021\n",
    ")\n",
    "lrc = LogisticRegression()\n",
    "lrc.fit(X_train, y_train)\n",
    "acc = lrc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc # 어익후 100프로가 나왔네 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 리그레서에서 원본데이터로 하려면 . 투덜투덜.\n",
    "그래서 cancer_std로 하는것이고 만약 원본데이터로 하려면 max_iter키워야해. \n",
    "맥스 이터란 그라디언트 디센트 방식을 반복해서 몇번 수행할 것인가 . \n",
    "\n",
    "철민이형 직접답면 \n",
    "안녕하십니까,\n",
    "\n",
    "사이킷런이 upgrade되면서 LogisticRegression에서 solver에 따른 warning 메시지가 나오곤 합니다.\n",
    "\n",
    "이 solver는  Gradient Descent와 같이 weight 값을 최적화 하는 유형들을 구분한 것입니다. max_iter는 Gradient Descent 방식을 반복해서 몇번 수행할 것인가 인데, 이게 일단 수렴(Convergence)하게 되면 횟수를 늘려도 성능이 거의 달라지지 않습니다.  따라서 500, 1000, 2000을 넣어도 일단 수렴이 된 후에 반복은 성능이 달라지지 않았기 때문에 같은 결과를 나타낸걸로 보시면 될 것 같습니다.\n",
    "\n",
    "그리고 노트북성능은 실습 코드를 돌린 제 노트북은 2.5GHZ 이며 Memory는 8G입니다.\n",
    "\n",
    "수행 속도가 느린것은 저도 원인을 모르겠습니다. 일단 max_iter가 5배 정도 증가했으니, 최대 5배 시간이 걸릴텐데, 한 12배 이상 시간이 걸리신것 같습니다. 혹 CPU 병렬이 차이가 있을 수도 있습니다.\n",
    "\n",
    "제 노트북은 Physical 2 Core, 4 Thread입니다.  command 창에서 msinfo32 로 확인해 보실 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer_pca, cancer.target, stratify=cancer.target, test_size=0.2, random_state=2021\n",
    ")\n",
    "lrc = LogisticRegression()\n",
    "lrc.fit(X_train, y_train)\n",
    "acc = lrc.score(X_test, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀의 pca 정확도 함수. \n",
    "def pca_accuracy(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y,  random_state=2021, test_size=0.2\n",
    "    )\n",
    "    lrc = LogisticRegression()\n",
    "    lrc.fit(X_train, y_train)\n",
    "    acc = lrc.score(X_test, y_test)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원 데이터1.0000\n",
      "PCA 2: , 정확도 0.9649, 설명력 0.6324\n",
      "PCA 5: , 정확도 0.9912, 설명력 0.8473\n",
      "PCA 10: , 정확도 0.9912, 설명력 0.9516\n"
     ]
    }
   ],
   "source": [
    "for n in [0, 2, 5, 10]:\n",
    "    if n == 0:\n",
    "        acc = pca_accuracy(cancer_std, cancer.target)\n",
    "        print(f'원 데이터{acc:.4f}')\n",
    "    else :\n",
    "        pca = PCA(n_components=n)\n",
    "        cancer_pca = pca.fit_transform(cancer_std)\n",
    "        explained = sum(pca.explained_variance_ratio_)\n",
    "        acc = pca_accuracy(cancer_pca, cancer.target)\n",
    "        print(f'PCA {n}: , 정확도 {acc:.4f}, 설명력 {explained:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 10: 설명력 0.9516, 정확도 0.9650\n",
      "PCA 5: 설명력 0.8473, 정확도 0.9650\n",
      "PCA 2: 설명력 0.6324, 정확도 0.9441\n"
     ]
    }
   ],
   "source": [
    "# for n in [10,5,2]:\n",
    "#     pca = PCA(n_components=n)\n",
    "#     br_pca = pca.fit_transform(br_std)\n",
    "#     explained = sum(pca.explained_variance_ratio_)\n",
    "#     acc = pca_accuracy(br_pca, br.target)\n",
    "#     print(f'PCA {n}: 설명력 {explained:.4f}, 정확도 {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 n_components=가 None 라면?#  \n",
    "# PCA(n_components=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cancer_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "cancer_pca = pca.fit_transform(cancer_std)\n",
    "df['PC1'] = cancer_pca[:, 0]\n",
    "df['PC2'] = cancer_pca[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    x_data = df[df.target == i]['PC1']\n",
    "    y_data = df[df.target == i]['PC2']\n",
    "    plt.scatter(x_data, y_data, label = cancer.target_names[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markers = ['^', 's', 'o']\n",
    "# for i, markers in enumerate(markers):\n",
    "#     x_data = df[df.target == i]['PC1']\n",
    "#     y_data = df[df.target == i]['PC2']\n",
    "#     plt.scatter(x_data, y_data, marker = markers, label = wine.target_names[i])\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('PCA Component 1')\n",
    "# plt.ylabel('PCA Component 2')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
